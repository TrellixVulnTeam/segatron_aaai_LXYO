{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm_notebook\n",
    "import re\n",
    "\n",
    "input_dir = 'out_txts'\n",
    "output_file = 'bookcorpus_lines.json'\n",
    "\n",
    "def getListOfFiles(dirName):\n",
    "    # create a list of file and sub directories\n",
    "    # names in the given directory\n",
    "    listOfFile = os.listdir(dirName)\n",
    "    allFiles = list()\n",
    "    # Iterate over all the entries\n",
    "    for entry in listOfFile:\n",
    "        # Create full path\n",
    "        fullPath = os.path.join(dirName, entry)\n",
    "        # If entry is a directory then get the list of files in this directory\n",
    "        if os.path.isdir(fullPath):\n",
    "            allFiles = allFiles + getListOfFiles(fullPath)\n",
    "        else:\n",
    "            allFiles.append(fullPath)\n",
    "\n",
    "    return allFiles\n",
    "\n",
    "def no_english(line):\n",
    "    english_check = re.compile(r'.*[a-zA-Z]+.*')\n",
    "    if re.match(english_check, line):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "def is_split_line(line):\n",
    "    words = line.strip().split()\n",
    "    word_num = len(words)\n",
    "    if word_num==0:\n",
    "        return False\n",
    "    if word_num<=10:\n",
    "        if no_english(line):\n",
    "            return True\n",
    "        if 'chapter' in line.lower():\n",
    "            return True        \n",
    "        if 'part' in line.lower():\n",
    "            return True\n",
    "        if words[0][0].isdigit():\n",
    "            return True\n",
    "    if word_num == 1 and words[0][0].isupper():\n",
    "        return True\n",
    "    return False\n",
    "def remove_header(all_lines):\n",
    "    top_1000 = all_lines[:1000]\n",
    "    for index,line in enumerate(top_1000):\n",
    "        if index>=len(top_1000)-5:\n",
    "            return None\n",
    "        if is_split_line(line):\n",
    "            if is_split_line(top_1000[index+1]) or is_split_line(top_1000[index+2]) or is_split_line(top_1000[index+3]) or is_split_line(top_1000[index+4]):\n",
    "                continue\n",
    "            break\n",
    "    return all_lines[index:]\n",
    "def split_docs(lines):\n",
    "    return None\n",
    "def judge_newline(lines):\n",
    "    sample_lines = [l for l in lines[len(lines)//4:len(lines)//2] if len(l.strip().split())>8]\n",
    "    count_end_with_alphabet = sum([1 for l in sample_lines if l.strip()[-1].isalpha()])\n",
    "    if count_end_with_alphabet/len(sample_lines)>0.3:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "listOfFiles = getListOfFiles(input_dir)\n",
    "ab = []\n",
    "with open(output_file,'w') as ofile:\n",
    "    for input_file in tqdm_notebook(listOfFiles,total=len(listOfFiles)):\n",
    "        with open(input_file, 'r') as ifile:\n",
    "            book_str = ifile.readlines()\n",
    "            lines = remove_header(book_str)\n",
    "            if not lines:\n",
    "                lines = book_str\n",
    "            try:\n",
    "                newline_para = judge_newline(lines)\n",
    "            except:\n",
    "                ab.append(input_file)\n",
    "                continue\n",
    "            parsed = {}\n",
    "            paragraphs = []\n",
    "            if newline_para:\n",
    "                # separated with \\n\n",
    "                for line in lines:\n",
    "                    words = line.strip().split()\n",
    "                    if '.jpg' in line:\n",
    "                        continue\n",
    "                    alpha_words = [w if w != \"\" and w[0].isaplha for w in words]\n",
    "                    if len(alpha_words)<6:\n",
    "                        if paragraphs==[] or len(' '.join(paragraphs))<100:\n",
    "                            paragraphs=[]\n",
    "                            continue\n",
    "                        else:\n",
    "                            parsed['text'] = '\\n'.join(paragraphs)\n",
    "                            parsed['book'] = input_file\n",
    "                            if len(parsed['text'])>=500:\n",
    "                                ofile.write(json.dumps(parsed) + '\\n')\n",
    "                            paragraphs=[]\n",
    "                            parsed = {}\n",
    "                    else:\n",
    "                        paragraphs.append(line.strip())\n",
    "#                         if len(paragraphs)>=128:\n",
    "#                             parsed['text'] = '\\n'.join(paragraphs)\n",
    "#                             parsed['book'] = input_file\n",
    "#                             if len(parsed['text'])>=500:\n",
    "#                                 ofile.write(json.dumps(parsed) + '\\n')\n",
    "#                             paragraphs=[]\n",
    "#                             parsed = {}\n",
    "                    parsed['text'] = '\\n'.join(paragraphs)\n",
    "                    parsed['book'] = input_file\n",
    "                    if len(parsed['text'])>=500:\n",
    "                        ofile.write(json.dumps(parsed) + '\\n')\n",
    "                    paragraphs=[]\n",
    "                    parsed = {}\n",
    "                else:\n",
    "                    stack = []\n",
    "                    for line in lines:\n",
    "                        words = line.strip().split()\n",
    "                        if '.jpg' in line:\n",
    "                            continue\n",
    "                        alpha_words = [w if w != \"\" and w[0].isaplha for w in words]\n",
    "                        if len(alpha_words)<6:\n",
    "                            if stack:\n",
    "                                if stack[-1][-1].isalpha() and len(words)==1:\n",
    "                                    stack.append(line.strip())\n",
    "                                    continue\n",
    "                                paragraphs.append(\" \".join(stack).strip().replace('\\n', ' '))\n",
    "                                stack = []\n",
    "                                if len(paragraphs)>=6 and len(' '.join(paragraphs))>5000:\n",
    "                                    parsed['text'] = '\\n'.join(paragraphs)\n",
    "                                    parsed['book'] = input_file\n",
    "                                    if len(parsed['text'])>=500:\n",
    "                                        ofile.write(json.dumps(parsed) + '\\n')\n",
    "                                    paragraphs=[]\n",
    "                                    parsed = {}\n",
    "                                    stack = []\n",
    "                            if paragraphs==[] or len(' '.join(paragraphs))<100:\n",
    "                                paragraphs=[]\n",
    "                                continue\n",
    "                            else:\n",
    "                                parsed['text'] = '\\n'.join(paragraphs)\n",
    "                                parsed['book'] = input_file\n",
    "                                if len(parsed['text'])>=500:\n",
    "                                    ofile.write(json.dumps(parsed) + '\\n')\n",
    "                                paragraphs=[]\n",
    "                                parsed = {}\n",
    "                                stack = []\n",
    "                        else:\n",
    "                            stack.append(line.strip())\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}